{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# I. Initialization Code",
   "id": "a93dd5014c4f0efc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T01:04:03.366537Z",
     "start_time": "2025-01-28T01:04:03.315798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "481c67eb4ed41555",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T01:04:03.819895Z",
     "start_time": "2025-01-28T01:04:03.806347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.genAIClient import GenerativeAIClient\n",
    "client = GenerativeAIClient()"
   ],
   "id": "d2b30958328e89d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 20:04:03,816 - INFO - Google Generative AI API configured successfully.\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# I. APE\n",
    "## 1."
   ],
   "id": "bba467b7e2795fc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T18:24:30.698542Z",
     "start_time": "2025-01-28T18:24:27.723018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.genAIClient import GenerativeAIClient\n",
    "\n",
    "client=GenerativeAIClient()\n",
    "\n",
    "system=\"\"\"You are a world-leading expert in LLM prompt engineering.\n",
    "You will be given a prompt template enclosed in <prompt> tag, the prompt may have input variables enclosed in braces.\n",
    "\n",
    "# Task\n",
    "Your job is to optimize and improve the given <prompt> using prompt engineering best practices.\n",
    "\n",
    "# Definition\n",
    "Prompt engineering is the process of discovering prompts which reliably yield useful or desired results.\n",
    "\n",
    "# Prompt Engineering best practices include:\n",
    "1. Give Clear Instructions - Outline exactly what you expect the LLM to do, use strong verbs and avoid ambiguity.\n",
    "2. Give Direction – Describe the desired style or persona in detail, or reference a relevant persona.\n",
    "3. Specify Format – Define what rules to follow, and the required structure of the response.\n",
    "4. Provide Examples – Insert a diverse set of examples that can be used for guidance.\n",
    "\"\"\"\n",
    "\n",
    "requirements = \"\"\"\n",
    "# Requirements\n",
    "1. Ensure that all the elements of \"Prompt Engineering best practices\" are present in the final prompt.\n",
    "2. Include at least 2-3 new sets of examples that are different from those in the <prompt>.\n",
    "3. Respond only with your optimized prompt template, DO NOT EXPLAIN HOW IT WAS OPTIMIZED.\n",
    "\"\"\"\n",
    "\n",
    "prompt=\"\"\"\n",
    "<prompt>\n",
    "Give me a list of product names for: {product_description}\n",
    "\n",
    "# Examples:\n",
    "Product Description 1: \"a shoe that can fit any foot size\"\n",
    "Product names: AdaptSoles, OmniFit, iFitWalkers, ShapeShift\n",
    "<\\\\prompt>\n",
    "\"\"\"\n",
    "\n",
    "output=client.invoke(prompt, system + requirements)\n",
    "print(output)\n",
    "# print(prompt)"
   ],
   "id": "d399835e51696d3a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 13:24:27,734 - INFO - Google Generative AI API configured successfully.\n",
      "2025-01-28 13:24:27,735 - INFO - Initialized model: gemini-pro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a comprehensive list of product names for the following {product_description}:\n",
      "\n",
      "# Instructions\n",
      "- Include a variety of names that encompass the product's key features and benefits.\n",
      "- Ensure the names are catchy, memorable, and relevant to the target audience.\n",
      "- Avoid using generic or overly descriptive names.\n",
      "\n",
      "# Examples:\n",
      "- Product Description 1: \"a virtual assistant that helps with tasks and scheduling\"\n",
      "   - Product names: AssistAI, TimeBuddy, TaskGenie, IntelliButler\n",
      "- Product Description 2: \"a smart lock that can be opened with a fingerprint or smartphone\"\n",
      "   - Product names: BioLock, SmartKey, FingerLock, iKey\n",
      "- Product Description 3: \"a portable charger that can charge multiple devices wirelessly\"\n",
      "   - Product names: PowerNow, ChargeAnywhere, WirelessBoost, EnergiGo\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# II. APE",
   "id": "d18240799c6cd067"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.\n",
    "### 1.1\n",
    "### 1.2"
   ],
   "id": "fa23df25e50a8e65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T18:06:39.415908Z",
     "start_time": "2025-01-28T18:06:39.404221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "requirements = \"\"\"\n",
    "# Requirements\n",
    "Your prompt template must take context from the user in the form of relevant input variables surrounded by curly brackets i.e. {input_variable}. These placeholders should be labelled in the template as they will be replaced with values when the prompt is used. Your prompt should provide multiple examples of different values the input variables might take, and what the expected responses would be in these test cases.\n",
    "\n",
    "Respond only with your optimized prompt template.\n",
    "\"\"\""
   ],
   "id": "4accaee55c9295a",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T18:06:41.767595Z",
     "start_time": "2025-01-28T18:06:41.756896Z"
    }
   },
   "cell_type": "code",
   "source": "print(requirements)",
   "id": "bc17eff6eb6dd4cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Requirements\n",
      "Your prompt template must take context from the user in the form of relevant input variables surrounded by curly brackets i.e. {input_variable}. These placeholders should be labelled in the template as they will be replaced with values when the prompt is used. Your prompt should provide multiple examples of different values the input variables might take, and what the expected responses would be in these test cases.\n",
      "\n",
      "Respond only with your optimized prompt template.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T18:06:44.669526Z",
     "start_time": "2025-01-28T18:06:42.908109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output=client.invoke(prompt, system + requirements)\n",
    "print(output)"
   ],
   "id": "c862f4a4caefc878",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a list of unique and creative product names for: {product_description}\n",
      "\n",
      "# Examples:\n",
      "- Product Description 1: \"a shoe that can fit any foot size\"\n",
      "- Product name examples: AdaptSoles, OmniFit, iFitWalkers, ShapeShift\n",
      "- Product Description 2: \"a self-cleaning water bottle\"\n",
      "- Product name examples: AquaCleanse, HydraPure, EverPure, H2Oasis\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d7ca542a158967c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
