{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# I. Initialization Code",
   "id": "a93dd5014c4f0efc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T01:04:03.366537Z",
     "start_time": "2025-01-28T01:04:03.315798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "481c67eb4ed41555",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T01:04:03.819895Z",
     "start_time": "2025-01-28T01:04:03.806347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.genAIClient import GenerativeAIClient\n",
    "client = GenerativeAIClient()"
   ],
   "id": "d2b30958328e89d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 20:04:03,816 - INFO - Google Generative AI API configured successfully.\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# I. Automatic Prompt Engineer (APE)\n",
    "## 1."
   ],
   "id": "bba467b7e2795fc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T22:38:33.785920Z",
     "start_time": "2025-02-11T22:38:30.115717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.genAIClient import GenerativeAIClient\n",
    "\n",
    "client=GenerativeAIClient()\n",
    "\n",
    "system=\"\"\"You are a world-leading expert in LLM prompt engineering.\n",
    "You will be given a prompt template enclosed in <prompt> tag, the prompt may have input variables enclosed in braces.\n",
    "\n",
    "# Task\n",
    "Your job is to optimize and improve the given <prompt> using prompt engineering best practices.\n",
    "\n",
    "# Definition\n",
    "Prompt engineering is the process of discovering prompts which reliably yield useful or desired results.\n",
    "\n",
    "# Prompt Engineering best practices include:\n",
    "1. Give Clear Instructions - Outline exactly what you expect the LLM to do, use strong verbs and avoid ambiguity.\n",
    "2. Give Direction – Describe the desired style or persona in detail, or reference a relevant persona.\n",
    "3. Specify Format – Define what rules to follow, and the required structure of the response.\n",
    "4. Provide Examples – Insert a diverse set of examples that can be used for guidance.\n",
    "\"\"\"\n",
    "\n",
    "requirements = \"\"\"\n",
    "# Requirements\n",
    "1. Ensure that all the elements of \"Prompt Engineering best practices\" are present in the final prompt.\n",
    "2. Include at least 2-3 new sets of examples that are different from those in the <prompt>.\n",
    "3. Respond only with your optimized prompt template, DO NOT EXPLAIN HOW IT WAS OPTIMIZED.\n",
    "\"\"\"\n",
    "\n",
    "prompt=\"\"\"\n",
    "<prompt>\n",
    "Give me a list of product names for: {product_description}\n",
    "\n",
    "# Examples:\n",
    "Product Description 1: \"a shoe that can fit any foot size\"\n",
    "Product names: AdaptSoles, OmniFit, iFitWalkers, ShapeShift\n",
    "<\\\\prompt>\n",
    "\"\"\"\n",
    "\n",
    "output=client.invoke(prompt, system + requirements)\n",
    "print(output)\n",
    "# print(prompt)"
   ],
   "id": "d399835e51696d3a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 17:38:30,386 - INFO - Google Generative AI API configured successfully.\n",
      "2025-02-11 17:38:30,386 - INFO - Initialized model: gemini-pro\n",
      "2025-02-11 17:38:30,486 - INFO - Prompt Tokens: \n",
      "total_tokens: 305\n",
      "\n",
      "2025-02-11 17:38:33,781 - INFO - Token Stats: \n",
      "prompt_token_count: 306\n",
      "candidates_token_count: 195\n",
      "total_token_count: 501\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<prompt>\n",
      "Provide a list of product names that aptly describe the product's key features: {product_description}.\n",
      "\n",
      "# Examples:\n",
      "**Product Description 1:** \"a shoe that can fit any foot size\"\n",
      "**Product names:**\n",
      "  - AdaptSoles: Emphasizes adaptability to different foot sizes.\n",
      "  - OmniFit: Conveys the idea of universal fit.\n",
      "  - iFitWalkers: Highlights the intelligent fitting technology.\n",
      "  - ShapeShift: Suggests the shoe's ability to conform to various foot shapes.\n",
      "\n",
      "**Product Description 2:** \"a backpack that is both durable and stylish\"\n",
      "**Product names:**\n",
      "  - DuraStyle: Combines \"durability\" and \"style.\"\n",
      "  - VoyagerX: Implies adventure and durability.\n",
      "  - Sentinel: Conveys protection and toughness.\n",
      "  - UrbanTrek: Highlights the backpack's suitability for urban environments.\n",
      "<\\prompt>\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# II. APE",
   "id": "d18240799c6cd067"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.\n",
    "### 1.1\n",
    "### 1.2"
   ],
   "id": "fa23df25e50a8e65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "requirements = \"\"\"\n",
    "# Requirements\n",
    "Your prompt template must take context from the user in the form of relevant input variables surrounded by curly brackets i.e. {input_variable}. These placeholders should be labelled in the template as they will be replaced with values when the prompt is used. Your prompt should provide multiple examples of different values the input variables might take, and what the expected responses would be in these lib cases.\n",
    "\n",
    "Respond only with your optimized prompt template.\n",
    "\"\"\""
   ],
   "id": "3d9505c874c333a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(requirements)",
   "id": "e9b49517c86ccfc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T18:06:44.669526Z",
     "start_time": "2025-01-28T18:06:42.908109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output=client.invoke(prompt, system + requirements)\n",
    "print(output)"
   ],
   "id": "c862f4a4caefc878",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a list of unique and creative product names for: {product_description}\n",
      "\n",
      "# Examples:\n",
      "- Product Description 1: \"a shoe that can fit any foot size\"\n",
      "- Product name examples: AdaptSoles, OmniFit, iFitWalkers, ShapeShift\n",
      "- Product Description 2: \"a self-cleaning water bottle\"\n",
      "- Product name examples: AquaCleanse, HydraPure, EverPure, H2Oasis\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d7ca542a158967c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
